import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
import json
import re

# Load the data
def clean_csv_line(line):
    # Handle quoted strings with commas inside them
    parts = []
    in_quotes = False
    current_part = ''
    
    for char in line:
        if char == '"':
            in_quotes = not in_quotes
        elif char == ',' and not in_quotes:
            parts.append(current_part)
            current_part = ''
        else:
            current_part += char
    
    parts.append(current_part)
    return parts

def parse_csv_data(csv_text):
    lines = csv_text.strip().split('\n')
    header = clean_csv_line(lines[0])
    
    data = []
    for line in lines[1:]:
        values = clean_csv_line(line)
        row_data = dict(zip(header, values))
        data.append(row_data)
    
    return pd.DataFrame(data)

# Example raw data string - would be replaced with actual file content
raw_data = """femaDeclarationString,disasterNumber,state,declarationType,declarationDate,fyDeclared,incidentType,declarationTitle,ihProgramDeclared,iaProgramDeclared,paProgramDeclared,hmProgramDeclared,incidentBeginDate,incidentEndDate,disasterCloseoutDate,tribalRequest,fipsStateCode,fipsCountyCode,placeCode,designatedArea,declarationRequestNumber,lastIAFilingDate,incidentId,region,designatedIncidentTypes,lastRefresh,hash,id
FM-5529-OR,5529,OR,FM,2024-08-09T00:00:00.000Z,2024,Fire,LEE FALLS FIRE,0,0,1,1,2024-08-08T00:00:00.000Z,,,0,41,67,99067,Washington (County),24122,,2024081001,10,R,2024-08-27T18:22:14.800Z,ae87cf3c6ed795015b714af7166c7c295b2b67c7,09e3f81a-5e16-4b72-b317-1c64e0cfa59c
FM-5528-OR,5528,OR,FM,2024-08-06T00:00:00.000Z,2024,Fire,ELK LANE FIRE,0,0,1,1,2024-08-04T00:00:00.000Z,,,0,41,31,99031,Jefferson (County),24116,,2024080701,10,R,2024-08-27T18:22:14.800Z,432cf0995c47e3895cea696ede5621b810460501,59983f89-30bf-4888-b21b-62e8d57d9aac
EM-3626-KY,3626,KY,EM,2025-04-03T00:00:00.000Z,2025,Severe Storm,SEVERE STORMS STRAIGHT-LINE WINDS TORNADOES AND FLOODING,0,0,1,0,2025-04-02T00:00:00.000Z,,,0,21,145,99145,McCracken (County),25046,,2025040102,4,2 W F T,2025-04-04T13:01:39.645Z,3cf6664759d84726f3ad960f41cabb34b70f341c,46bd23f0-8108-4af8-a9f4-8c193a6e9e9e
EM-3626-KY,3626,KY,EM,2025-04-03T00:00:00.000Z,2025,Severe Storm,SEVERE STORMS STRAIGHT-LINE WINDS TORNADOES AND FLOODING,0,0,1,0,2025-04-02T00:00:00.000Z,,,0,21,147,99147,McCreary (County),25046,,2025040102,4,2 W F T,2025-04-04T13:01:39.645Z,60c01fe66dd833b99452e16a9054cb4085561f22,e0d91942-0c45-40ef-9c6c-d41034a99c9b"""

# Let's assume we have more data - for a proper model we'd need much more
# This would come from the actual CSV file
extended_data = raw_data + """
DR-4751-MI,4751,MI,DR,2024-08-01T00:00:00.000Z,2024,Flood,SEVERE STORMS FLOODING AND TORNADOES,1,1,1,1,2024-07-08T00:00:00.000Z,2024-07-12T00:00:00.000Z,,0,26,163,99163,Wayne (County),24112,2024-10-02T00:00:00.000Z,2024070801,5,F T,2024-08-27T18:22:14.800Z,f9a5f8e3a5ed9bf5c10f1a39c3cc1ff1240a4f47,8a1a5f2a-1e32-4b77-b4f1-c5c4f70f1e5d
DR-4751-MI,4751,MI,DR,2024-08-01T00:00:00.000Z,2024,Flood,SEVERE STORMS FLOODING AND TORNADOES,1,1,1,1,2024-07-08T00:00:00.000Z,2024-07-12T00:00:00.000Z,,0,26,161,99161,Washtenaw (County),24112,2024-10-02T00:00:00.000Z,2024070801,5,F T,2024-08-27T18:22:14.800Z,5a0a3e3b4c4d8e9f1a2b3c4d5e6f7a8b9c0d1e2,8b2b6f3b-2f43-5c88-c5f2-d6d5f81f2f6e
DR-4750-CA,4750,CA,DR,2024-07-25T00:00:00.000Z,2024,Fire,WILDFIRES,1,1,1,1,2024-07-17T00:00:00.000Z,2024-07-24T00:00:00.000Z,,0,06,037,99037,Los Angeles (County),24109,2024-09-25T00:00:00.000Z,2024071701,9,F,2024-08-27T18:22:14.800Z,1a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0,9c3c7f4c-3f54-6d99-d6f3-e7e6f92f3f7f
DR-4749-TX,4749,TX,DR,2024-07-22T00:00:00.000Z,2024,Drought,SEVERE DROUGHT,1,1,1,1,2024-06-01T00:00:00.000Z,2024-07-15T00:00:00.000Z,,0,48,201,99201,Harris (County),24104,2024-09-22T00:00:00.000Z,2024060101,6,Z,2024-08-27T18:22:14.800Z,2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1,0d4d8f5d-4f65-7e00-e7f4-f8f7f03f4f8f
DR-4748-FL,4748,FL,DR,2024-07-19T00:00:00.000Z,2024,Hurricane,HURRICANE BERYL,1,1,1,1,2024-07-08T00:00:00.000Z,2024-07-10T00:00:00.000Z,,0,12,057,99057,Hillsborough (County),24103,2024-09-19T00:00:00.000Z,2024070802,4,Z H,2024-08-27T18:22:14.800Z,3c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2,1e5e9f6e-5f76-8f11-f8f5-f9f8f14f5f9f
DR-4748-FL,4748,FL,DR,2024-07-19T00:00:00.000Z,2024,Hurricane,HURRICANE BERYL,1,1,1,1,2024-07-08T00:00:00.000Z,2024-07-10T00:00:00.000Z,,0,12,103,99103,Pinellas (County),24103,2024-09-19T00:00:00.000Z,2024070802,4,Z H,2024-08-27T18:22:14.800Z,4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3,2f6f0f7f-6f87-9f22-f9f6-f0f9f25f6f0f
DR-4747-GA,4747,GA,DR,2024-07-17T00:00:00.000Z,2024,Hurricane,HURRICANE BERYL,1,1,1,1,2024-07-08T00:00:00.000Z,2024-07-09T00:00:00.000Z,,0,13,051,99051,Chatham (County),24101,2024-09-17T00:00:00.000Z,2024070803,4,Z H,2024-08-27T18:22:14.800Z,5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4,3g7g1f8g-7f98-0f33-f0f7-f1f0f36f7g1f
DR-4746-AL,4746,AL,DR,2024-07-15T00:00:00.000Z,2024,Tornado,SEVERE STORMS AND TORNADOES,1,1,1,1,2024-07-04T00:00:00.000Z,2024-07-06T00:00:00.000Z,,0,01,073,99073,Jefferson (County),24098,2024-09-15T00:00:00.000Z,2024070401,4,T,2024-08-27T18:22:14.800Z,6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4x5,4h8h2g9h-8f09-1f44-f1f8-f2f1f47f8h2g
EM-3625-HI,3625,HI,EM,2024-06-28T00:00:00.000Z,2024,Flood,SEVERE STORMS FLOODING AND LANDSLIDES,0,0,1,0,2024-06-26T00:00:00.000Z,,,0,15,001,99001,Hawaii (County),24095,,2024062601,9,F L,2024-08-27T18:22:14.800Z,7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4x5y6,5i9i3h0i-9f10-2f55-f2f9-f3f2f58f9i3h
FM-5527-CA,5527,CA,FM,2024-06-27T00:00:00.000Z,2024,Fire,POST FIRE,0,0,1,1,2024-06-26T00:00:00.000Z,,,0,06,029,99029,Kern (County),24094,,2024062701,9,F,2024-08-27T18:22:14.800Z,8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4x5y6z7,6j0j4i1j-0f21-3f66-f3f0-f4f3f69f0j4i
DR-4745-IN,4745,IN,DR,2024-06-19T00:00:00.000Z,2024,Severe Storm,SEVERE STORMS STRAIGHT-LINE WINDS AND TORNADOES,1,1,1,1,2024-05-25T00:00:00.000Z,2024-05-27T00:00:00.000Z,,0,18,097,99097,Marion (County),24090,2024-08-20T00:00:00.000Z,2024052501,5,S T W,2024-08-27T18:22:14.800Z,9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4x5y6z7a8,7k1k5j2k-1f32-4f77-f4f1-f5f4f70f1k5j
DR-4744-AR,4744,AR,DR,2024-06-17T00:00:00.000Z,2024,Severe Storm,SEVERE STORMS AND TORNADOES,1,1,1,1,2024-05-24T00:00:00.000Z,2024-05-26T00:00:00.000Z,,0,05,119,99119,Pulaski (County),24089,2024-08-17T00:00:00.000Z,2024052402,6,S T,2024-08-27T18:22:14.800Z,0j1k2l3m4n5o6p7q8r9s0t1u2v3w4x5y6z7a8b9,8l2l6k3l-2f43-5f88-f5f2-f6f5f81f2l6k
DR-4743-MO,4743,MO,DR,2024-06-14T00:00:00.000Z,2024,Severe Storm,SEVERE STORMS STRAIGHT-LINE WINDS AND TORNADOES,1,1,1,1,2024-05-23T00:00:00.000Z,2024-05-25T00:00:00.000Z,,0,29,189,99189,St. Louis (County),24087,2024-08-14T00:00:00.000Z,2024052301,7,S T W,2024-08-27T18:22:14.800Z,1k2l3m4n5o6p7q8r9s0t1u2v3w4x5y6z7a8b9c0,9m3m7l4m-3f54-6f99-f6f3-f7f6f92f3m7l
FM-5525-AZ,5525,AZ,FM,2024-06-10T00:00:00.000Z,2024,Fire,TONTO CREEK FIRE,0,0,1,1,2024-06-08T00:00:00.000Z,,,0,04,007,99007,Gila (County),24083,,2024060801,9,F,2024-08-27T18:22:14.800Z,2l3m4n5o6p7q8r9s0t1u2v3w4x5y6z7a8b9c0d1,0n4n8m5n-4f65-7f00-f7f4-f8f7f03f4n8m
DR-4742-NY,4742,NY,DR,2024-06-04T00:00:00.000Z,2024,Flood,SEVERE WINTER STORM AND FLOODING,1,1,1,1,2024-04-16T00:00:00.000Z,2024-04-18T00:00:00.000Z,,0,36,047,99047,Kings (County),24081,2024-08-05T00:00:00.000Z,2024041601,2,Z F,2024-08-27T18:22:14.800Z,3m4n5o6p7q8r9s0t1u2v3w4x5y6z7a8b9c0d1e2,1o5o9n6o-5f76-8f11-f8f5-f9f8f14f5o9n
DR-4741-NJ,4741,NJ,DR,2024-06-01T00:00:00.000Z,2024,Flood,SEVERE WINTER STORM AND FLOODING,1,1,1,1,2024-04-13T00:00:00.000Z,2024-04-15T00:00:00.000Z,,0,34,013,99013,Essex (County),24079,2024-08-01T00:00:00.000Z,2024041301,2,Z F,2024-08-27T18:22:14.800Z,4n5o6p7q8r9s0t1u2v3w4x5y6z7a8b9c0d1e2f3,2p6p0o7p-6f87-9f22-f9f6-f0f9f25f6p0o
DR-4740-WA,4740,WA,DR,2024-05-29T00:00:00.000Z,2024,Flood,SEVERE WINTER STORM STRAIGHT-LINE WINDS FLOODING LANDSLIDES AND MUDSLIDES,1,1,1,1,2024-01-04T00:00:00.000Z,2024-01-09T00:00:00.000Z,,0,53,033,99033,King (County),24077,2024-07-29T00:00:00.000Z,2024010401,10,Z F L M W,2024-08-27T18:22:14.800Z,5o6p7q8r9s0t1u2v3w4x5y6z7a8b9c0d1e2f3g4,3q7q1p8q-7f98-0f33-f0f7-f1f0f36f7q1p
DR-4739-WV,4739,WV,DR,2024-05-25T00:00:00.000Z,2024,Severe Storm,SEVERE STORMS FLOODING LANDSLIDES AND MUDSLIDES,1,1,1,1,2024-04-11T00:00:00.000Z,2024-04-14T00:00:00.000Z,,0,54,039,99039,Kanawha (County),24075,2024-07-25T00:00:00.000Z,2024041101,3,2 F L M,2024-08-27T18:22:14.800Z,6p7q8r9s0t1u2v3w4x5y6z7a8b9c0d1e2f3g4h5,4r8r2q9r-8f09-1f44-f1f8-f2f1f47f8r2q"""

# Parse the CSV data into a DataFrame
df = parse_csv_data(extended_data)

# Convert relevant columns to appropriate types
df['fyDeclared'] = pd.to_numeric(df['fyDeclared'], errors='coerce')
df['incidentBeginDate'] = pd.to_datetime(df['incidentBeginDate'], errors='coerce')

# Extract year from incident date
df['incidentYear'] = df['incidentBeginDate'].dt.year

# Create features for each state
# Count disasters by type and year
state_disaster_counts = df.groupby(['state', 'incidentType']).size().unstack(fill_value=0)

# Calculate recency-weighted disaster counts (more recent disasters have higher weight)
current_year = 2025
df['yearsSinceIncident'] = current_year - df['incidentYear']
df['recencyWeight'] = 1 / (df['yearsSinceIncident'] + 1)  # +1 to avoid division by zero

recency_weighted_counts = df.groupby(['state', 'incidentType']).apply(
    lambda x: (x['recencyWeight']).sum()).unstack(fill_value=0)
recency_weighted_counts.columns = [f'{col}_weighted' for col in recency_weighted_counts.columns]

# Combine features
state_features = pd.concat([state_disaster_counts, recency_weighted_counts], axis=1)

# If a state has no disasters in our dataset, add it with zeros
all_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 
              'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 
              'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 
              'VA', 'WA', 'WV', 'WI', 'WY', 'DC']
for state in all_states:
    if state not in state_features.index:
        state_features.loc[state] = 0

# Fill NaNs with 0
state_features = state_features.fillna(0)

# Add a "total disasters" column
state_features['total_disasters'] = df.groupby('state').size()
state_features['total_disasters'] = state_features['total_disasters'].fillna(0)

# Create a synthetic risk score for demonstration purposes
# In a real model, we would use actual climate projections
# Here we'll use the recency-weighted counts as a proxy
risk_factors = {
    'Drought': 1.2,    # Multiplier for drought impact
    'Fire': 1.5,       # Multiplier for fire impact
    'Flood': 1.3,      # Multiplier for flood impact
    'Hurricane': 1.8,  # Multiplier for hurricane impact
    'Severe Storm': 1.4, # Multiplier for severe storm impact
    'Tornado': 1.6     # Multiplier for tornado impact
}

# Initialize risk score
state_features['risk_score'] = 0

# Calculate risk score based on weighted incident counts and risk factors
for incident_type in risk_factors:
    if f'{incident_type}_weighted' in state_features.columns:
        state_features['risk_score'] += state_features[f'{incident_type}_weighted'] * risk_factors[incident_type]
    elif incident_type in state_features.columns:
        # If weighted column doesn't exist, use raw count with a lower weight
        state_features['risk_score'] += state_features[incident_type] * (risk_factors[incident_type] * 0.5)

# Normalize risk score to 0-100 scale
if state_features['risk_score'].max() > 0:  # Avoid division by zero
    state_features['risk_score'] = (state_features['risk_score'] / state_features['risk_score'].max() * 100).round(1)

# Split data for training and validation
# In a real scenario, we would have actual climate projection data as the target
# Here we'll use current risk score as the target and other features to predict it
X = state_features.drop('risk_score', axis=1)
y = state_features['risk_score']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a model pipeline
numeric_features = X.columns.tolist()
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features)
    ])

model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(random_state=42))
])

# Train the model
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Model MSE: {mse:.2f}")
print(f"Model RÂ²: {r2:.2f}")

# Predict risk scores for all states
state_features['predicted_risk'] = model.predict(X).round(1)

# Prepare data for the map visualization
risk_categories = {
    'Very Low': (0, 20),
    'Low': (20, 40),
    'Medium': (40, 60),
    'High': (60, 80),
    'Very High': (80, 100)
}

# Assign risk category to each state
def get_risk_category(score):
    for category, (min_val, max_val) in risk_categories.items():
        if min_val <= score < max_val:
            return category
    return 'Very High'  # Default for scores >= 100

state_features['risk_category'] = state_features['predicted_risk'].apply(get_risk_category)

# Create color for each risk level
color_scale = {
    'Very Low': '#4575b4',  # Blue
    'Low': '#91bfdb',       # Light Blue
    'Medium': '#ffffbf',    # Yellow
    'High': '#fc8d59',      # Orange
    'Very High': '#d73027'  # Red
}

state_features['color'] = state_features['risk_category'].map(color_scale)

# Prepare data for the most common disaster types
top_disaster_types = {}
for state in state_features.index:
    disaster_columns = [col for col in state_features.columns if col not in 
                       ['risk_score', 'predicted_risk', 'risk_category', 'color', 'total_disasters'] 
                       and not col.endswith('_weighted')]
    
    if len(disaster_columns) > 0:
        disasters = state_features.loc[state, disaster_columns]
        if disasters.sum() > 0:
            top_disaster = disasters.idxmax()
        else:
            top_disaster = "No Data"
        top_disaster_types[state] = top_disaster
    else:
        top_disaster_types[state] = "No Data"

state_features['top_disaster'] = pd.Series(top_disaster_types)

# Generate predictions for the next year (simplified)
def predict_next_year_increase(row):
    # Calculate a synthetic increase prediction based on recent trends
    # In a real model, this would use climate projections and time series forecasting
    weighted_cols = [col for col in row.index if col.endswith('_weighted')]
    if len(weighted_cols) > 0 and row[weighted_cols].sum() > 0:
        recent_activity = row[weighted_cols].sum()
        # Higher recent activity suggests higher future risk increase
        return round(min(5 + recent_activity * 2, 15), 1)  # Cap at 15% increase
    return 5.0  # Default value

state_features['next_year_trend'] = state_features.apply(predict_next_year_increase, axis=1)

# Create JSON output for the web visualization
output_data = {}
for state in state_features.index:
    output_data[state] = {
        'riskScore': float(state_features.loc[state, 'predicted_risk']),
        'riskCategory': state_features.loc[state, 'risk_category'],
        'color': state_features.loc[state, 'color'],
        'topDisasterType': state_features.loc[state, 'top_disaster'] if pd.notna(state_features.loc[state, 'top_disaster']) else "No Data",
        'totalDisasters': int(state_features.loc[state, 'total_disasters']),
        'nextYearTrend': float(state_features.loc[state, 'next_year_trend'])
    }

# Save as JSON
with open('climate_risk_data.json', 'w') as f:
    json.dump(output_data, f)

print("Model training and evaluation complete.")
print(f"Risk scores generated for {len(output_data)} states.")
print("Data saved to climate_risk_data.json")

# Display sample of the results
print("\nSample risk scores:")
sample_states = ['CA', 'FL', 'TX', 'NY', 'MI']
for state in sample_states:
    if state in output_data:
        print(f"{state}: {output_data[state]['riskScore']} - {output_data[state]['riskCategory']} (Top disaster: {output_data[state]['topDisasterType']})")

# Convert the output_data to a JavaScript variable for direct inclusion in HTML
js_data = f"const climateRiskData = {json.dumps(output_data, indent=2)};"
with open('climate_risk_data.js', 'w') as f:
    f.write(js_data)

print("\nData also saved as JavaScript variable in climate_risk_data.js")